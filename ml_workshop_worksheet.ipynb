{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decreased-disease",
   "metadata": {},
   "source": [
    "# Machine Learning Workshop\n",
    "## 26 January 2021\n",
    "### Pinto Research Group \n",
    "### Workshop led by Ben Gincley and Chris Anderson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-agency",
   "metadata": {},
   "source": [
    "## About this dataset:\n",
    "The dataset includes 80x80pixel images of polystyrene microspheres used to calibrate instruments like flow cytometers or microscopes.<br /><br />\n",
    "The dataset is comprised of 4 microsphere sizes: 4.5um, 6um, 10um, and 15um microspheres.<br /><br />\n",
    "For Classification, class labels include both in-focus (if) and out-of-focus (oof) images of each size, as well as debris and background noise picked up on the digital microscope.<br />\n",
    "For Regression, the sphere size (in micrometers) is denoted in the 'object_size' column of the 'features' datatables. Debris and background are listed as having 'object_size' = 0.<br /><br />\n",
    "Sample sizes are as follows: In-Focus - 200 | Out-of-Focus - 100 | Debris/Background - 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io, img_as_float\n",
    "import support as s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-exemption",
   "metadata": {},
   "source": [
    "## Visualize Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdir = './data/_samples/'\n",
    "ic = io.ImageCollection(imdir+'*.png')\n",
    "len(ic)\n",
    "#plt.imshow(imcollection[0])\n",
    "cm = 'bone'\n",
    "f, axes = plt.subplots(nrows = 5, ncols = len(ic)//5, figsize=(5,10))\n",
    "axes = axes.ravel()\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "for i, image in enumerate(ic):\n",
    "    image = img_as_float(image)\n",
    "    axes[i].imshow(image,cmap=cm)\n",
    "    axes[i].set_title(os.path.basename(ic.files[i]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-paris",
   "metadata": {},
   "source": [
    "## Import and Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and create initial data table (dataframe)\n",
    "df = \n",
    "print(f\"Dataframe df shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe by printing first 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data distribution by plotting one or several features as a histogram:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-childhood",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-russell",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean up the data as needed, e.g. re-assign names to the classes and \n",
    "# combine in focus and out-of-focus labels\n",
    "\n",
    "reclassdict = \n",
    "labels = s.reClass(labels, reclassdict)\n",
    "unique_labels = labels.unique()\n",
    "\n",
    "print(f\"Unique Labels in unique_labels: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-gather",
   "metadata": {},
   "source": [
    "#### Note that 'labels' is a direct memory reference to the dataframe, so the dataframe can get rewritten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-philosophy",
   "metadata": {},
   "source": [
    "## Prepare inputs for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-nurse",
   "metadata": {},
   "source": [
    "#### Remove Target column(s) and any metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target and metadata columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-ownership",
   "metadata": {},
   "source": [
    "#### Prepare feature vector and class labels (target) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a list of feature names (for plotting), \n",
    "# an array of features (some models prefer an array instead of a table),\n",
    "# and normalize features (some models train much faster if scaled 0:1)\n",
    "feature_names = \n",
    "features = \n",
    "normalized_features = \n",
    "print(f\"Normalized Feature Vector: {normalized_features[0,:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string class names to integers (some models don't handle mapping outputs to strings well)\n",
    "\n",
    "print(f\"Unique classes (numerical): {unique_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-lyric",
   "metadata": {},
   "source": [
    "### Note: \n",
    "There is a method in sklearn.preprocessing called 'LabelEncoder()' that automates this, but the above adds a little more manual control over things like name order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine sample sizes of each class:\n",
    "sample_sizes = \n",
    "print(f\"Sample sizes: {sample_sizes}\")\n",
    "# Balance class weights for algorithms that take class weights as parameters:\n",
    "sample_weights = \n",
    "weights = {unique_classes[i]: sample_weights[i] for i in range(len(unique_classes))} \n",
    "print(f\"Class weights: {weights.values()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example...\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(class_weight = weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-belize",
   "metadata": {},
   "source": [
    "from the documentation...\n",
    "#### class_weight: dict, list of dict or “balanced”, default=None\n",
    "##### Weights associated with classes in the form {class_label: weight}. \n",
    "##### The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)) <br />\n",
    "Okay so it's already a built-in. Easy enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some more things for later...\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-anger",
   "metadata": {},
   "source": [
    "## Separate the Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(\n",
    ")\n",
    "print(f\"xTrain shape: {xTrain.shape}\")\n",
    "print(f\"xTest shape: {xTest.shape}\")\n",
    "print(f\"yTest shape: {yTest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-pitch",
   "metadata": {},
   "source": [
    "## Trying out our first model: Decision Tree Classifier\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-shipping",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3,max_leaf_nodes=6,criterion=\"entropy\",class_weight = 'balanced')\n",
    "clf.fit(xTrain,yTrain)\n",
    "yPredict = clf.predict(xTest)\n",
    "report = metrics.classification_report(yTest,yPredict)\n",
    "print(report)\n",
    "print(metrics.confusion_matrix(yTest, yPredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-webcam",
   "metadata": {},
   "source": [
    "Tune the hyperparameters (max_depth, max_leaf_nodes, etc.) to your heart's content until you get pretty dang good performance.\n",
    "But, how might this model perform on unseen data - unseen to both the model and the model architect? How can we fairly evaluate what we've created?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-carol",
   "metadata": {},
   "source": [
    "## Training, Validation, Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation-Test Split\n",
    "# Train is what the model sees and learns from\n",
    "# Validation provides feedback to you during training, to tune hyperparameters for better performance\n",
    "# Test is 'holdout' group of 'wild' data for final model evaluation\n",
    "\n",
    "# Separate Train-Validation and Test sets\n",
    "xTrainset, xTest, yTrainset, yTest = \n",
    "# Separate Train and Validation sets\n",
    "xTrain, xVal, yTrain, yVal = \n",
    "print(f\"yTrain shape: {yTrain.shape}\")\n",
    "print(f\"yVal shape: {yVal.shape}\")\n",
    "print(f\"yTest shape: {yTest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-rebel",
   "metadata": {},
   "source": [
    "### Train a new classifier and evaluate using Validation set, then test final result on Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-exposure",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier( )\n",
    "yValPredict = clf.predict(xVal)\n",
    "report = metrics.classification_report(yVal,yValPredict)\n",
    "print(metrics.confusion_matrix(yVal, yValPredict))\n",
    "print(report)\n",
    "print(f\"Val Accuracy: {np.round(metrics.accuracy_score(yVal,yValPredict),4)}\")\n",
    "print(f\"Val Precision: {np.round(metrics.precision_score(yVal,yValPredict,average='weighted'),4)}\")\n",
    "print(f\"Val Recall: {np.round(metrics.recall_score(yVal,yValPredict,average='weighted'),4)}\")\n",
    "\n",
    "# Final evaluation with help from support function to plot confusion matrix\n",
    "yTestPredict = clf.predict(xTest)\n",
    "s.confusionMatrixFxn(yTest,yTestPredict,unique_labels,title_add = 'Basic Decision Tree',\n",
    "                     cm=plt.cm.Blues)\n",
    "print(f\"Test Accuracy: {np.round(metrics.accuracy_score(yTest,yTestPredict),4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-triple",
   "metadata": {},
   "source": [
    "But again, how can we be sure that the validation set we're working from is representative of the whole sample? Changing the 'random_state' can have noticeable impact on performance..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-accountability",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html <br />\n",
    "Split the Test set off from most of our data, then iteratively create multiple validation subsets within our TrainingSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with cross validation:\n",
    "# Separate Train-Validation and Test sets\n",
    "xTrainset, xTest, yTrainset, yTest = train_test_split(normalized_features, class_labels, \n",
    "                                                    test_size=0.15,random_state=1)\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion=\"entropy\", class_weight = 'balanced', max_depth=8,\n",
    "                             max_leaf_nodes=8, min_impurity_decrease=0.001)\n",
    "\n",
    "scores = cross_val_score(tree, xTrainset, yTrainset, cv=5)\n",
    "for n, cv in enumerate(scores):\n",
    "    print(f\"CV fold {n}: {np.round(cv,4)}\")\n",
    "print(f\"Mean: {np.round(scores.mean(),4)}, StDev: {np.round(scores.std(),4)}\")\n",
    "# Final evaluation with help from support function to plot confusion matrix\n",
    "tree.fit(xTrainset,yTrainset)\n",
    "yTestPredict = tree.predict(xTest)\n",
    "s.confusionMatrixFxn(yTest,yTestPredict,unique_labels,title_add = 'Decision Tree',cm=plt.cm.Greens)\n",
    "print(f\"Test Accuracy: {np.round(metrics.accuracy_score(yTest,yTestPredict),4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-smoke",
   "metadata": {},
   "source": [
    "Mean of 5-fold cross validation very close to test accuracy - this makes it a pretty good predictor of test performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-milan",
   "metadata": {},
   "source": [
    "### A Note on Time Series Data:\n",
    "TimeSeriesSplit is a variation of k-fold which returns first k folds as train set and the (k+1) th fold as test set. Note that unlike standard cross-validation methods, successive training sets are supersets of those that come before them. Also, it adds all surplus data to the first training partition, which is always used to train the model.\n",
    "\n",
    "This class can be used to cross-validate time series data samples that are observed at fixed time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[9, 8], [7, 6], [9, 8], [7, 6], [9, 8], [7, 6]])\n",
    "y = np.array([0, 1, 2, 3, 4, 5])\n",
    "print(\"X Vector:\")\n",
    "print(X)\n",
    "print(\"Y Vector:\")\n",
    "print(y)\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "for n, (train, test) in enumerate(tscv.split(X)):\n",
    "     print(f\"CV: {n} | Train: {train} | Test: {test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-background",
   "metadata": {},
   "source": [
    "#### Try tweaking the hyperparameters to see if performance can improve..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-fundamental",
   "metadata": {},
   "source": [
    "Okay, so as fun as it is to mess with hyperparameters...I've got other things to do. Can I automate this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-sigma",
   "metadata": {},
   "source": [
    "Yes! Several approaches to finding performance maxima in hyperparameter space:<br />\n",
    "https://blog.ml.cmu.edu/2018/12/12/massively-parallel-hyperparameter-optimization/<br />\n",
    "And, they can be used in tandem. For example: a random search to find a promising region, then detailed grid search within that region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-sponsorship",
   "metadata": {},
   "source": [
    "## Automated Hyperparameter Tuning with Grid Searches\n",
    "Random grid search, Brute-force grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-newark",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Random Search\n",
    "# Number of features to consider at every split\n",
    "class_weights = ['balanced', None]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(3, 40, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum impurity\n",
    "min_impurity_decrease = [float(x) for x in np.linspace(0, 0.01, num = 10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 8]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 8]\n",
    "# Method of selecting samples for training each tree\n",
    "# Create the random grid\n",
    "random_grid = {'class_weight': class_weights,\n",
    "               'max_depth': max_depth,\n",
    "               #'min_samples_split:': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'min_impurity_decrease': min_impurity_decrease}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "dt = DecisionTreeClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 20 different combinations, and use all available cores\n",
    "dt_random = RandomizedSearchCV(estimator = dt, param_distributions = random_grid, \n",
    "                               n_iter = 20, cv = 3, verbose=2, random_state=2, n_jobs = -1)\n",
    "# Fit the random search iterator to the data\n",
    "dt_random.fit(xTrain, yTrain)\n",
    "print(f\"Optimum from random search: {dt_random.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brute-Force Grid Search\n",
    "param={'max_depth':(np.arange(10,20)),\n",
    "       'min_samples_split':(np.arange(2,6)),\n",
    "       'min_samples_leaf':(np.arange(1,4)),\n",
    "       'min_impurity_decrease':(np.arange(7,10)/1000)}\n",
    "\n",
    "#dt = DecisionTreeClassifier()\n",
    "gridS=GridSearchCV(estimator = DecisionTreeClassifier(), \n",
    "                   param_grid = param, cv=5, verbose=1)\n",
    "\n",
    "gridS.fit(xTrain,yTrain)\n",
    "print(f\"Optimum from grid search: {gridS.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimum model\n",
    "optitree = DecisionTreeClassifier(criterion=\"entropy\", class_weight = None, max_depth=15,\n",
    "                             max_leaf_nodes=40, min_impurity_decrease=0.007,\n",
    "                            min_samples_leaf = 1, min_samples_split = 5)\n",
    "optitree.fit(xTrainset,yTrainset)\n",
    "yTestPredict = optitree.predict(xTest)\n",
    "s.confusionMatrixFxn(yTest,yTestPredict,unique_labels,title_add = 'Search-Optimized Decision Tree',cm=plt.cm.Purples)\n",
    "print(f\"Test Accuracy: {np.round(metrics.accuracy_score(yTest,yTestPredict),4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-orleans",
   "metadata": {},
   "source": [
    "I think we've squeezed this lemon (tree) for all its juice...what do you mean \"more trees?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-placement",
   "metadata": {},
   "source": [
    "## Ensemble Learning: Random Forest\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "## Random Forest\n",
    "rf = RandomForestClassifier(n_estimators = 24, criterion = 'gini', max_depth = 8, random_state = 2)\n",
    "rf.fit(xTrainset, yTrainset);\n",
    "rf_predictions = rf.predict(xTest)\n",
    "\n",
    "errors = np.not_equal(yTest,rf_predictions)\n",
    "nErrors = np.sum(errors)\n",
    "errorRate = nErrors/len(yTest)\n",
    "accuracy = 100*(1-errorRate)\n",
    "\n",
    "print(f\"Test Accuracy: {np.round(metrics.accuracy_score(yTest,rf_predictions),4)}\")\n",
    "s.confusionMatrixFxn(yTest,rf_predictions,unique_labels,title_add = 'Random Forest',cm=plt.cm.Oranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-fairy",
   "metadata": {},
   "source": [
    "So how are these models achieving such high accuracy? Are a small handful of features really important, or does everything contribute a little bit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-wonder",
   "metadata": {},
   "source": [
    "## Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importances from Decision Tree\n",
    "# Find important values\n",
    "importances = optitree.feature_importances_\n",
    "feature_importances = [(feature, round(importance, 3)) for feature, importance in zip(feature_names, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "print(f\"Top 5 features of ranked importance: {feature_importances[0:5]}\")\n",
    "plt.figure()\n",
    "plt.barh(feature_names,importances,color='g')\n",
    "plt.title(\"Feature Importances, Single Tree\")\n",
    "plt.xlim([0,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-deputy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Feature Importances from Forest\n",
    "# Find important values\n",
    "importances = rf.feature_importances_\n",
    "feature_importances = [(feature, round(importance, 3)) for feature, importance in zip(feature_names, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "print(feature_importances[0:5])\n",
    "plt.figure()\n",
    "plt.barh(feature_names,importances,color='orange')\n",
    "plt.title(\"Feature Importances, Random Forest\")\n",
    "plt.xlim([0,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-future",
   "metadata": {},
   "source": [
    "The Random Forest allows full feature set to be more 'democratic' if there are no 1:1 feature:class relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-nightmare",
   "metadata": {},
   "source": [
    "## Random Forest Regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remake our datatable:\n",
    "root_directory= './data/_features/'\n",
    "df_list = s.importData(root_directory,'.csv', verbose=False)\n",
    "df = s.concatenateDFs(df_list)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure 'Target' column looks correct:\n",
    "target = df['object_size']\n",
    "print(target.shape)\n",
    "print(np.unique(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove background and debris for now:\n",
    "df_filtered = df[df['object_size'] > 0]\n",
    "target = df_filtered['object_size']\n",
    "print(f\"Sample size: {target.shape}\")\n",
    "print(f\"Unique values: {np.unique(target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for model input:\n",
    "df_filtered = df_filtered.drop(columns=['patchID','patchsize','object_size'])\n",
    "feature_names = list(df.columns)\n",
    "features = np.asarray(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Train-Validation and Test sets\n",
    "xTrainset, xTest, yTrainset, yTest = train_test_split(features, target, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFRegressor = RandomForestRegressor()\n",
    "# Score the model (default = R^2)\n",
    "scores = cross_val_score(RFRegressor, xTrainset, yTrainset, cv=5)\n",
    "for n, cv in enumerate(scores):\n",
    "    print(f\"CV fold {n}: {np.round(cv,4)}\")\n",
    "print(f\"Mean: {np.round(scores.mean(),4)}, StDev: {np.round(scores.std(),4)}\")\n",
    "RFRegressor.fit(xTrainset,yTrainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-cannon",
   "metadata": {},
   "source": [
    "Already looking pretty dang good for the default parameters!<br />\n",
    "And now the final test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfregTestPredict = RFRegressor.predict(xTest)\n",
    "lims = [4,15.5]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(yTest,rfregTestPredict,color='orange',marker='o',s=140,alpha=0.4)\n",
    "plt.plot(lims,lims,'-.',c='gray',alpha=0.8)\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.title(f\"Default Random Forest Regressor on Object Sizes, n={len(yTest)}\")\n",
    "plt.xlabel(\"Ground Truth\")\n",
    "plt.ylabel(\"Regressor Output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-relation",
   "metadata": {},
   "source": [
    "If you wanted to get fancy, you can map the distance from ground truth to a color scale, but this is fine for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it:\n",
    "n = 15\n",
    "predictions = RFRegressor.predict(xTest[0:n])\n",
    "resultsdf = pd.DataFrame(columns=['Predictions','GroundTruth'])\n",
    "resultsdf['Predictions'] = predictions\n",
    "resultsdf['GroundTruth'] = yTest[0:n].values\n",
    "resultsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = metrics.mean_squared_error(rfregTestPredict,yTest)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error: {np.round(rmse,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-saskatchewan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature Importances from Random Forest Regressor\n",
    "# Find important values\n",
    "importances = RFRegressor.feature_importances_\n",
    "feature_importances = [(feature, round(importance, 3)) for feature, importance in zip(feature_names, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "print(\"Top 10 features in rank of importance:\")\n",
    "for feature in feature_importances[0:10]:\n",
    "    print(feature[0])\n",
    "    print(feature[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-photographer",
   "metadata": {},
   "source": [
    "#### So which should you use? Classifier or Regressor? Depends on the underlying data type: <br />\n",
    "##### If your data is categorical and non-continuous: Classifier<br /><br />\n",
    "##### If your data is non-categorical and continuous: Regressor<br /><br />\n",
    "##### If your data is categorical and continuous: Classifier or Regressor could work<br />\n",
    "(example) Microbeads are sold at discrete sizes, but manufacturing defects create variance around a mean size. Further, the target variable/feature is size/diameter, an inherently continuous measurement. This wouldn't work so well for a taxonomic target!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-russell",
   "metadata": {},
   "source": [
    "### Another way to visualize variation between classes:\n",
    "## Principal Component Analysis (PCA)\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is from after running the \"clean data\" cell\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(columns=['celltype','patchID','patchsize','object_size'])\n",
    "x = StandardScaler().fit_transform(df2)\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['pc1', 'pc2'])\n",
    "finalDf = pd.concat([principalDf, df_full[['celltype']]], axis = 1)\n",
    "\n",
    "finalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "sns.scatterplot(data = finalDf, x = \"pc1\", y = \"pc2\", \n",
    "                hue = \"celltype\", marker = \"o\", linewidth=0, s = 20, alpha = 0.7\n",
    "               )\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_xlim([-10, 20])\n",
    "ax.set_ylim([-5, 15])\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper left', bbox_to_anchor=(1.0, 1.0), frameon = True).set_title('')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
